{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Marketplace Product Usage Demonstration - 7Park Data transaction data parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7Park Data** transaction data parsing allows you to wrangle more value out of your credit card, POS, and receipt data by identifying and extracting key entities. \n",
    "\n",
    "Our transaction data classifier (NER) has been trained and optimized on trillions of credit card transactions over the last 5 years. Entities covered in this solution include: \n",
    "- **Merchants / Companies** (e.g., \"Starbucks\")\n",
    "- **Locations** (e.g., \"Venice Beach, Los Angeles, CA\")\n",
    "\n",
    "F1 scores are 95% and higher for all entities on our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample notebook requires subscription to the following pre-trained machine learning model packages from AWS Marketplace:\n",
    "\n",
    "**[Transaction Data Parsing (NER)](https://aws.amazon.com/marketplace/pp/prodview-sqnwjvzzqntn2)**\n",
    "    \n",
    "If your AWS account has not been subscribed to these listings, here is the process you can follow for each of the above mentioned listings:\n",
    "\n",
    "1. Open the listing from AWS Marketplace\n",
    "1. Read the **Highlights** section and then **product overview** section of the listing.\n",
    "1. View **usage information** and then **additional resources.**\n",
    "1. Note the supported instance types.\n",
    "1. Next, click on **Continue to subscribe.**\n",
    "1. Review **End user license agreement, support terms**, as well as **pricing information.**\n",
    "1. **\"Accept Offer\"** button needs to be clicked if your organization agrees with EULA, pricing information as well as support terms.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "If **Continue to configuration** button is active, it means your account already has a subscription to this listing.\n",
    "Once you click on **Continue to configuration** button and then choose region, you will see that a Product Arn will appear. This is the model package ARN that you need to specify while creating a deployable model. However, for this notebook, the algorithm ARN has been specified in **src/model_package_arns.py** file and you do not need to specify the same explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment and view a sample image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will import necessary libraries and define variables such as an S3 bucket, an IAM role, and sagemaker session to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "\n",
    "from src.model_package_arns import ModelPackageArnProvider\n",
    "\n",
    "# role = get_execution_role()\n",
    "role = 'arn:aws:iam::084888172679:role/service-role/AmazonSageMaker-ExecutionRole-20181114T165487'\n",
    "\n",
    "sagemaker_session = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Inference Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Deploy the model for performing real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------"
     ]
    }
   ],
   "source": [
    "# Get the model_package_arn\n",
    "modelpackage_arn = ModelPackageArnProvider.get_model_package_arn(sagemaker_session.boto_region_name)\n",
    "\n",
    "# Define predictor wrapper class\n",
    "def ner_detection_predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session, content_type='application/json')\n",
    "\n",
    "# Create a deployable model for the transaction data parsing model package.\n",
    "ner_model = ModelPackage(role=role,\n",
    "                         model_package_arn=modelpackage_arn,\n",
    "                         sagemaker_session=sagemaker_session,\n",
    "                         predictor_cls=ner_detection_predict_wrapper)\n",
    "\n",
    "# Deploy the model\n",
    "ner_predictor = ner_model.deploy(initial_instance_count=1, \n",
    "                                 instance_type='ml.m5.xlarge',\n",
    "                                 endpoint_name='txn-ner-endpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Perform a prediction on Amazon Sagemaker Endpoint created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {'instance': '63212 THE HOMEDEPOT 9325 LUBBOCK TX'}\n",
    "\n",
    "# Perform a prediction\n",
    "ner_result = ner_predictor.predict(json.dumps(sample)).decode('utf-8')\n",
    "\n",
    "# View the prediction\n",
    "pprint(json.loads(ner_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Transform Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the model built to run a batch inference job and verify it works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model supports data in [jsonlines](http://jsonlines.org/) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": 0, \"instance\": \"02/07 THE HOME DEPOT 0561 MIDLAND TX\"}\n",
      "{\"id\": 1, \"instance\": \"NST THE HOME-Depot 682011 7545 N MESA & REMCON EL PASO TX\"}\n",
      "{\"id\": 2, \"instance\": \"63212 THE HOMEDEPOT 9325 LUBBOCK TX\"}\n",
      "{\"id\": 3, \"instance\": \"01-23 THE HOME DEP 7943 FLUSHING NY\"}\n",
      "{\"id\": 4, \"instance\": \"DUNKIn #352275 Q ROCKWALL TX\"}\n",
      "{\"id\": 5, \"instance\": \"SA DUNKIN #293874 Q BRENHAM TX\"}\n",
      "{\"id\": 6, \"instance\": \"Da DUNKIN donuts CA\"}\n",
      "{\"id\": 7, \"instance\": \"ASMW DUNKIN-DONUTS MA\"}\n",
      "{\"id\": 8, \"instance\": \"Wal-Mart Su 0321 WAL-MARTS BRENHAM TX\"}\n",
      "{\"id\": 9, \"instance\": \"MURPHY 6781 AT WALMRT TEXARKANA AR\"}\n",
      "{\"id\": 10, \"instance\": \"wal-Mart #4367 TEXARKANA TX\"}\n",
      "{\"id\": 11, \"instance\": \"SW 2738 WAL-marts CA\"}\n"
     ]
    }
   ],
   "source": [
    "# review input file\n",
    "SAMPLE_FILE = 'data/samples.jl'\n",
    "\n",
    "with open(SAMPLE_FILE) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Update the input file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_input = sagemaker_session.upload_data(\n",
    "    SAMPLE_FILE, \n",
    "    key_prefix='transaction_ner/' + SAMPLE_FILE)\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run a new transform job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import uuid\n",
    "\n",
    "transformer = ner_model.transformer(1, 'ml.m5.xlarge', \n",
    "                                    accept=\"application/jsonlines\",\n",
    "                                    assemble_with='Line')\n",
    "transformer.transform(\n",
    "    transform_input, \n",
    "    content_type='application/jsonlines',\n",
    "    join_source= \"Input\",\n",
    "    split_type='Line'\n",
    ")\n",
    "transformer.wait()\n",
    "\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Inspect the Batch Transform Output in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"SageMakerOutput\":{\"ner\":[{\"end_pos\":9,\"key\":\"THE\",\"start_pos\":6,\"type\":\"NE_MERCHANT\"},{\"end_pos\":14,\"key\":\"HOME\",\"start_pos\":10,\"type\":\"NE_MERCHANT\"},{\"end_pos\":20,\"key\":\"DEPOT\",\"start_pos\":15,\"type\":\"NE_MERCHANT\"},{\"end_pos\":33,\"key\":\"MIDLAND\",\"start_pos\":26,\"type\":\"NE_STORE_LOCATION\"},{\"end_pos\":36,\"key\":\"TX\",\"start_pos\":34,\"type\":\"NE_STORE_LOCATION\"}]},\"id\":0,\"instance\":\"02/07 THE HOME DEPOT 0561 MIDLAND TX\"}\n",
      "{\"SageMakerOutput\":{\"ner\":[{\"end_pos\":7,\"key\":\"THE\",\"start_pos\":4,\"type\":\"NE_MERCHANT\"},{\"end_pos\":12,\"key\":\"HOME\",\"start_pos\":8,\"type\":\"NE_MERCHANT\"},{\"end_pos\":13,\"key\":\"-\",\"start_pos\":12,\"type\":\"NE_MERCHANT\"},{\"end_pos\":18,\"key\":\"Depot\",\"start_pos\":13,\"type\":\"NE_MERCHANT\"},{\"end_pos\":32,\"key\":\"N\",\"start_pos\":31,\"type\":\"NE_STORE_LOCATION\"},{\"end_pos\":37,\"key\":\"MESA\",\"start_pos\":33,\"type\":\"NE_STORE_LOCATION\"},{\"end_pos\":39,\"key\":\"\\u0026\",\"start_pos\":38,\"type\":\"NE_MERCHANT\"},{\"end_pos\":46,\"key\":\"REMCON\",\"start_pos\":40,\"type\":\"NE_MERCHANT\"},{\"end_pos\":49,\"key\":\"EL\",\"start_pos\"...\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "parsed_url = urlparse(transformer.output_path)\n",
    "bucket_name = parsed_url.netloc\n",
    "file_key = '{}/{}.out'.format(parsed_url.path[1:], \"samples.jl\")\n",
    "\n",
    "s3_client = sagemaker_session.boto_session.client('s3')\n",
    "\n",
    "response = s3_client.get_object(Bucket = sagemaker_session.default_bucket(), Key = file_key)\n",
    "response_bytes = response['Body'].read().decode('utf-8')\n",
    "\n",
    "print(response_bytes[:1000] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_predictor.delete_endpoint()\n",
    "ner_predictor.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if the AWS Marketplace subscription was created just for an experiment and you would like to unsubscribe, here are the steps that can be followed. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model.\n",
    "\n",
    "**Steps to unsubscribe from the product on AWS Marketplace:**\n",
    "\n",
    "Navigate to Machine Learning tab on Your [Software subscriptions page](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=lbr_tab_ml).\n",
    "Locate the listing that you would need to cancel, and click Cancel Subscription."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
